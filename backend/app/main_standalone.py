"""
Perso.ai Q&A Chatbot - Cohere API Version
ë°°í¬ì— ìµœì í™”ëœ ë²„ì „ (ë¬´ë£Œ API ì‚¬ìš©)
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pydantic_settings import BaseSettings
from typing import List, Dict, Optional
from functools import lru_cache
import cohere
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import uuid
import os

# ==================== ì„¤ì • ====================

class AppSettings(BaseSettings):
    COHERE_API_KEY: str = ""
    QDRANT_COLLECTION_NAME: str = "perso_qa"
    SIMILARITY_THRESHOLD: float = 0.7
    TOP_K: int = 3
    
    class Config:
        env_file = ".env"
        case_sensitive = True
        extra = "ignore"

@lru_cache()
def get_settings():
    return AppSettings()

settings = get_settings()

# ==================== ì„ë² ë”© ì„œë¹„ìŠ¤ ====================

class EmbeddingService:
    def __init__(self):
        if not settings.COHERE_API_KEY:
            raise ValueError("COHERE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.client = cohere.Client(settings.COHERE_API_KEY)
        self.model = "embed-multilingual-v3.0"  # í•œêµ­ì–´ ì§€ì›
        print(f"âœ… Cohere ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_embedding(self, text: str) -> List[float]:
        try:
            response = self.client.embed(
                texts=[text],
                model=self.model,
                input_type="search_document"  # ë¬¸ì„œ ì €ì¥ìš©
            )
            return response.embeddings[0]
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def get_query_embedding(self, text: str) -> List[float]:
        try:
            response = self.client.embed(
                texts=[text],
                model=self.model,
                input_type="search_query"  # ê²€ìƒ‰ ì¿¼ë¦¬ìš©
            )
            return response.embeddings[0]
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def rerank(self, query: str, documents: List[str]) -> List[Dict]:
        """Cohere Rerank APIë¡œ ê²°ê³¼ ì¬ì •ë ¬"""
        try:
            response = self.client.rerank(
                query=query,
                documents=documents,
                model="rerank-multilingual-v3.0",
                top_n=3
            )
            return response.results
        except Exception as e:
            print(f"âš ï¸ Rerank ì‹¤íŒ¨, ê¸°ë³¸ ê²°ê³¼ ì‚¬ìš©: {e}")
            return None

# ==================== ë²¡í„° ìŠ¤í† ì–´ ====================

class VectorStore:
    def __init__(self, embedding_service: EmbeddingService):
        # ë°°í¬ í™˜ê²½ì—ì„œëŠ” :memory: ì‚¬ìš© (ì˜êµ¬ ì €ì¥ ë¶ˆí•„ìš”)
        self.client = QdrantClient(location=":memory:")
        self.collection_name = settings.QDRANT_COLLECTION_NAME
        self.embedding_service = embedding_service
        self.initialized = False
    
    def initialize_collection(self, vector_size: int):
        try:
            self.client.recreate_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(
                    size=vector_size,
                    distance=Distance.COSINE
                )
            )
            self.initialized = True
            print(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}' ìƒì„± ì™„ë£Œ (ë²¡í„° í¬ê¸°: {vector_size})")
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def add_documents(self, qa_pairs: List[Dict[str, str]]):
        if not self.initialized:
            sample_embedding = self.embedding_service.get_embedding(qa_pairs[0]['question'])
            self.initialize_collection(vector_size=len(sample_embedding))
        
        points = []
        for idx, qa in enumerate(qa_pairs):
            # ì§ˆë¬¸ë§Œ ì„ë² ë”© (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
            embedding = self.embedding_service.get_embedding(qa['question'])
            
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=embedding,
                payload={
                    "question": qa['question'],
                    "answer": qa['answer'],
                    "index": idx
                }
            )
            points.append(point)
            print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {idx + 1}/{len(qa_pairs)} - {qa['question'][:40]}...")
        
        self.client.upsert(
            collection_name=self.collection_name,
            points=points
        )
        print(f"âœ… ì´ {len(points)}ê°œì˜ Q&A ë°ì´í„° ì €ì¥ ì™„ë£Œ\n")
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        try:
            query_embedding = self.embedding_service.get_query_embedding(query)
            search_result = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=top_k
            )
            
            results = []
            for hit in search_result:
                results.append({
                    "question": hit.payload['question'],
                    "answer": hit.payload['answer'],
                    "score": hit.score,
                    "index": hit.payload['index']
                })
            return results
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_best_answer(self, query: str) -> Optional[Dict]:
        # Top 3 ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ ë¶„ì„
        results = self.search(query, top_k=3)
        if not results:
            return None
        
        best_match = results[0]
        
        # ë””ë²„ê¹…ìš© ì¶œë ¥
        print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼ for '{query}':")
        for i, r in enumerate(results[:3], 1):
            print(f"  {i}. [{r['score']:.3f}] {r['question'][:50]}...")
        
        # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë‹µë³€ ëª» ì°¾ìŒ
        if best_match['score'] < settings.SIMILARITY_THRESHOLD:
            return {
                "question": query,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Perso.aiì— ëŒ€í•œ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.",
                "score": best_match['score'],
                "found": False
            }
        
        return {
            "question": best_match['question'],
            "answer": best_match['answer'],
            "score": best_match['score'],
            "found": True
        }

# ==================== FastAPI ì•± ====================

app = FastAPI(
    title="Perso.ai Q&A Chatbot API",
    description="ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì§€ì‹ê¸°ë°˜ ì±—ë´‡ (Cohere Embedding)",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
embedding_service = None
vector_store = None

# Request/Response ëª¨ë¸
class QueryRequest(BaseModel):
    question: str

class QueryResponse(BaseModel):
    question: str
    answer: str
    score: float
    found: bool

class HealthResponse(BaseModel):
    status: str
    message: str

# Q&A ë°ì´í„°
QA_DATA = [
    {
        "question": "Perso.aiëŠ” ì–´ë–¤ ì„œë¹„ìŠ¤ì¸ê°€ìš”?",
        "answer": "Perso.aiëŠ” ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸ê°€ ê°œë°œí•œ ë‹¤êµ­ì–´ AI ì˜ìƒ ë”ë¹™ í”Œë«í¼ìœ¼ë¡œ, ëˆ„êµ¬ë‚˜ ì–¸ì–´ì˜ ì¥ë²½ ì—†ì´ ì˜ìƒì„ ì œì‘í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” AI SaaS ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "answer": "Perso.aiëŠ” AI ìŒì„± í•©ì„±, ë¦½ì‹±í¬, ì˜ìƒ ë”ë¹™ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì›ë³¸ ì˜ìƒì— ë‹¤ë¥¸ ì–¸ì–´ë¡œ ìŒì„±ì„ ì…íˆê±°ë‚˜, ì… ëª¨ì–‘ê¹Œì§€ ìë™ìœ¼ë¡œ ë™ê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiëŠ” ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
        "answer": "Perso.aiëŠ” ElevenLabs, Microsoft, Google Cloud Speech API ë“±ê³¼ ê°™ì€ ê¸€ë¡œë²Œ ê¸°ìˆ  íŒŒíŠ¸ë„ˆì˜ ìŒì„±í•©ì„± ë° ë²ˆì—­ ê¸°ìˆ ì„ í™œìš©í•˜ë©°, ìì²´ ê°œë°œí•œ ë¦½ì‹±í¬ ì—”ì§„ì„ ê²°í•©í•©ë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiì˜ ì‚¬ìš©ìëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
        "answer": "2025ë…„ ê¸°ì¤€, ì „ ì„¸ê³„ ëˆ„ì  20ë§Œ ëª… ì´ìƒì˜ ì‚¬ìš©ìê°€ Perso.aië¥¼ í†µí•´ AI ê¸°ë°˜ ì˜ìƒ ì œì‘ì„ ê²½í—˜í–ˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "Perso.aië¥¼ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” ê³ ê°ì¸µì€ ëˆ„êµ¬ì¸ê°€ìš”?",
        "answer": "ìœ íŠœë²„, ê°•ì˜ ì œì‘ì, ê¸°ì—… ë§ˆì¼€íŒ… ë‹´ë‹¹ì ë“± ì˜ìƒ ì½˜í…ì¸ ë¥¼ ë‹¤êµ­ì–´ë¡œ í™•ì¥í•˜ë ¤ëŠ” ê°œì¸ ë° ê¸°ì—… ê³ ê°ì´ ì£¼ìš” íƒ€ê¹ƒì…ë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ëŠ” ëª‡ ê°œì¸ê°€ìš”?",
        "answer": "í˜„ì¬ 30ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì§€ì›í•˜ë©°, í•œêµ­ì–´, ì˜ì–´, ì¼ë³¸ì–´, ìŠ¤í˜ì¸ì–´, í¬ë¥´íˆ¬ê°ˆì–´ ë“± ì£¼ìš” ì–¸ì–´ê°€ í¬í•¨ë©ë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiì˜ ìš”ê¸ˆì œëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?",
        "answer": "Perso.aiëŠ” ì‚¬ìš©ëŸ‰ ê¸°ë°˜ êµ¬ë… ëª¨ë¸ì„ ìš´ì˜í•©ë‹ˆë‹¤. Free, Creator, Pro, Enterprise í”Œëœì´ ìˆìœ¼ë©° Stripeë¥¼ í†µí•´ ê²°ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiëŠ” ì–´ë–¤ ê¸°ì—…ì´ ê°œë°œí–ˆë‚˜ìš”?",
        "answer": "Perso.aiëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê¸°ì—… ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸(ESTsoft)ê°€ ê°œë°œí–ˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸ëŠ” ì–´ë–¤ íšŒì‚¬ì¸ê°€ìš”?",
        "answer": "ì´ìŠ¤íŠ¸ì†Œí”„íŠ¸ëŠ” 1993ë…„ì— ì„¤ë¦½ëœ IT ê¸°ì—…ìœ¼ë¡œ, ì•Œì§‘, ì•Œì•½, ì•Œì”¨ ë“± ìƒí™œí˜• ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ì„œë¹„ìŠ¤ ê°œë°œì— ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "Perso.aiì˜ ê¸°ìˆ ì  ê°•ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "answer": "AI ìŒì„± í•©ì„±ê³¼ ë¦½ì‹±í¬ ì •í™•ë„ê°€ ë†’ê³ , ë‹¤êµ­ì–´ ì˜ìƒ ì œì‘ì´ ê°„í¸í•˜ë©°, ì‹¤ì œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ê°€ ì§ê´€ì ì´ë¼ëŠ” ì ì´ ê°•ì ì…ë‹ˆë‹¤."
    },
    {
        "question": "Perso.aië¥¼ ì‚¬ìš©í•˜ë ¤ë©´ íšŒì›ê°€ì…ì´ í•„ìš”í•œê°€ìš”?",
        "answer": "ë„¤, ì´ë©”ì¼ ë˜ëŠ” êµ¬ê¸€ ê³„ì •ìœ¼ë¡œ ê°„ë‹¨íˆ íšŒì›ê°€ì… í›„ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "Perso.aië¥¼ ì´ìš©í•˜ë ¤ë©´ ì˜ìƒ í¸ì§‘ ì§€ì‹ì´ í•„ìš”í•œê°€ìš”?",
        "answer": "ì•„ë‹ˆìš”. Perso.aiëŠ” ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì–´ ìˆì–´, ì˜ìƒ í¸ì§‘ ê²½í—˜ì´ ì—†ì–´ë„ ë°”ë¡œ ë”ë¹™ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "Perso.ai ê³ ê°ì„¼í„°ëŠ” ì–´ë–»ê²Œ ë¬¸ì˜í•˜ë‚˜ìš”?",
        "answer": "Perso.ai ì›¹ì‚¬ì´íŠ¸ í•˜ë‹¨ì˜ 'ë¬¸ì˜í•˜ê¸°' ë²„íŠ¼ì„ í†µí•´ ì´ë©”ì¼ ë˜ëŠ” ì±„íŒ…ìœ¼ë¡œ ê³ ê°ì„¼í„°ì— ë¬¸ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    }
]

@app.on_event("startup")
async def startup_event():
    global embedding_service, vector_store
    print("\n" + "="*60)
    print("ğŸš€ Perso.ai Q&A Chatbot ì‹œì‘ (Cohere API)")
    print("="*60 + "\n")
    
    try:
        print("1ï¸âƒ£ Cohere ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        embedding_service = EmbeddingService()
        
        print("\n2ï¸âƒ£ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì¤‘...")
        vector_store = VectorStore(embedding_service)
        
        print("\n3ï¸âƒ£ Q&A ë°ì´í„° ë²¡í„°í™” ì‹œì‘...")
        vector_store.add_documents(QA_DATA)
        
        print("="*60)
        print("âœ… ëª¨ë“  ì´ˆê¸°í™” ì™„ë£Œ! ì±—ë´‡ ì„œë¹„ìŠ¤ ì¤€ë¹„ë¨")
        print("="*60 + "\n")
    except Exception as e:
        print(f"\nâŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

@app.get("/", response_model=HealthResponse)
async def root():
    return {
        "status": "ok",
        "message": "Perso.ai Q&A Chatbot API is running (Cohere Embedding)"
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    return {
        "status": "healthy",
        "message": "All systems operational"
    }

@app.post("/query", response_model=QueryResponse)
async def query_chatbot(request: QueryRequest):
    try:
        if not request.question.strip():
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        result = vector_store.get_best_answer(request.question)
        if not result:
            raise HTTPException(status_code=500, detail="ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        return QueryResponse(**result)
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/test-search")
async def test_search(q: str = "Perso.aië€?"):
    results = vector_store.search(q, top_k=3)
    return {
        "query": q,
        "results": results
    }

if __name__ == "__main__":
    import uvicorn
    print("ğŸŒ ì„œë²„ ì‹œì‘: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)